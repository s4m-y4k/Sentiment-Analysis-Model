# Sentiment-Analysis-Model

Sentiment analysis refers to the class of computational and Natural language processing-based techniques used to identify, extract or characterize subjective information, such as opinions, expressed in a given piece of text. The main purpose of sentiment analysis is to classify a writer’s attitude towards various topics into positive, negative or neutral categories. Sentiment analysis has many applications in different domains including, but not limited to, business intelligence, politics, sociology, etc.
Sentiment are feelings, opinions, emotions, likes/dislikes, good/bad. Sentiment Analysis is a Natural Language Processing and Information Extraction task that aims to obtain writer’s feelings expressed in positive, negative or complex comments, questions and requests by analysing a large number of documents. Sentiment Analysis is a study of human behaviour in which we extract user opinion and emotion from plain text. It is also known as Opinion Mining. It identifies the opinion or attitude that a person has towards a topic or an object.

Example:

Comments:                                                                                           Polarity:
i.	Person A: It’s a great movie.                           			                                  (Positive)
ii.	Person B: Nah!! I didn’t like it at all…           			                                        (Negative)
iii.	Person C: The new Restaurant is okay…        			                                            (Neutral)

Project Objective & Scope

In this project, a Sentiment Analysis system is modelled using Naive-Bayes algorithm and natural Language Processing. We will use Naive-Bayes algorithm and a BoW (Bag of Words) dictionary as a classifier. 
Automatically analysing consumer feedback, such as opinions in survey responses and social media conversations, allows brands to learn what makes consumer happy or frustrated, so that they can tailor products and services to meet their consumer’s needs.
Recent years, on the other hand, have witnessed the advent of social networking websites, microblogs, wikis and Web applications and consequently, an unprecedented growth in user-generated data is poised for sentiment mining. Data such as web-postings, Tweets, videos, etc., all express opinions on various topics and events, offer immense opportunities to study and analyse human opinions and sentiment. Since consumers express their thoughts and feelings more openly than ever before, sentiment analysis is becoming an essential tool to monitor and understand that sentiment. 

Literature Survey

Our day-to-day life has always been influenced by what people think. Ideas and opinions of others have always affected our own opinions. The explosion of Web 2.0 has led to increased activity in Podcasting, Blogging, Tagging, Contributing to RSS, Social Bookmarking, and Social Networking. As a result, there has been an eruption of interest in people to mine these vast resources of data for opinions. Sentiment Analysis or Opinion Mining is the computational treatment of opinions, sentiments and subjectivity of text. 
In this report, we take a look at the various challenges and applications of Sentiment Analysis. We will discuss in details various approaches to perform a computational treatment of sentiments and opinions. Various supervised or data-driven techniques to SA like Naïve Byes, Maximum Entropy, SVM, and Voted Perceptron will be discussed and their strengths and drawbacks will be touched upon. We will also see a new dimension of analysing sentiments by Cognitive Psychology mainly through the work of Janyce Wiebe, where we will see ways to detect subjectivity, perspective in narrative and understanding the discourse structure. We will also study some specific topics in Sentiment Analysis and the contemporary works in those areas.

Case Study 

	Machine Learning

The machine learning based text classifiers are a kind of supervised machine learning paradigm, where the classifier needs to be trained on some labelled training data before it can be applied to actual classification tasks. The training data is usually a extracted portion of the original data hand labelled manually. After suitable training they can be used on the actual test data. The Naive Bayes is a statistical classifier whereas Support Vector Machine is a kind of vector space classifier. The statistical text classifier scheme of Naive-Bayes (NB) can be adapted to be used for sentiment classification problems as it can be visualized as a 2-class text classification problem: in positive and negative classes.


	Natural Language Processing

Natural Language Processing (NLP) is a field at the intersection of computer science, artificial intelligence, and linguistics. The goal is for computers to process or “understand” natural language in order to perform various human like tasks like language translation or answering questions. With the rise of voice interfaces and chatbots, NLP is one of the most important technologies of the 4th Industrial Revolution and become a popular area of AI. There’s a fast-growing collection of useful applications derived from the NLP field. They range from simple to complex. Below are a few of them:
•	Search, spell checking, keyword search, finding synonyms, complex questions answering
•	Extracting information from websites such as: products, price, dates, locations, people or names
•	Machine translation (i.e., Google translate), speech recognition, personal assistants (think about Amazon Alexa, Apple Siri, Facebook M, Google Assistant or Microsoft Cortana)
•	Chat bots/dialog agents for customer support, controlling devices, ordering goods
•	Matching online advertisements, sentiment analysis for marketing or finance/trading
•	Identifying financials risks or fraud

	Naive-Bayes Classifier

In statistics, naive Bayes classifiers are a family of simple "probabilistic classifiers" based on applying Bayes' theorem with strong (naïve) independence assumptions between the features (see Bayes classifier). They are among the simplest Bayesian network models, but coupled with kernel density estimation, they can achieve higher accuracy levels.
Naïve Bayes classifiers are highly scalable, requiring a number of parameters linear in the number of variables (features/predictors) in a learning problem. Maximum-likelihood training can be done by evaluating a closed-form expression, which takes linear time, rather than by expensive iterative approximation as used for many other types of classifiers.
In the statistics and computer science literature, naive Bayes models are known under a variety of names, including simple Bayes and independence Bayes. All these names reference the use of Bayes' theorem in the classifier's decision rule, but naïve Bayes is not (necessarily) a Bayesian method.

